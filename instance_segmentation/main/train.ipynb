{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgz9xWpVsDcx",
        "outputId": "18b5d1f0-064e-4975-c46e-6df05772c417",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Download Mask RCNN Repository\n",
        "! git clone https://github.com/matterport/Mask_RCNN.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Mask_RCNN' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrN-ctmnsRN7",
        "outputId": "606179da-070a-4fce-9b5b-bb4f5bc6e464",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "# installing dependency for google collab\n",
        "!pip uninstall -y tensorflow\n",
        "!pip uninstall -y tensorflow-gpu\n",
        "!pip install tensorflow-gpu==1.14.0\n",
        "!pip install keras==2.1.3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\n",
            "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\n",
            "Collecting tensorflow-gpu==1.14.0\n",
            "  Using cached https://files.pythonhosted.org/packages/76/04/43153bfdfcf6c9a4c38ecdb971ca9a75b9a791bb69a764d652c359aca504/tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.32.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.35.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (3.12.4)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14.0) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.14.0) (50.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.2.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-1.14.0\n",
            "Requirement already satisfied: keras==2.1.3 in /usr/local/lib/python3.6/dist-packages (2.1.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.3) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.3) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.1.3) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.1.3) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUW6MhZo35s5",
        "outputId": "ac3cba96-b1cd-42e0-d8d2-79abcd786934",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "# silent tf verbose\n",
        "tf.get_logger().setLevel('INFO')\n",
        "# check to see if gpu is used\n",
        "K.tensorflow_backend._get_available_gpus()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/job:localhost/replica:0/task:0/device:GPU:0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTY0O9m2sToc"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "from imgaug import augmenters as iaa\n",
        "import numpy as np"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OczqHWG1D2L"
      },
      "source": [
        "# Root directory of the project\n",
        "# When drive is mounted, prepend content \n",
        "ROOT_DIR = os.path.join('Mask_RCNN')\n",
        "sys.path.append(ROOT_DIR)\n",
        "# append mounted google drive to path for using mrcnn\n",
        "GDRIVE_DATASET_PATH  = os.path.join('drive','My Drive','Colab Notebooks','mask_rcnn')\n",
        "sys.path.append(GDRIVE_DATASET_PATH)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP-eDNLoueWM"
      },
      "source": [
        "# Global variables after path is mounted\n",
        "# path/gdrive path where the model is saved\n",
        "MODEL_PERS_DIR = os.path.join(GDRIVE_DATASET_PATH, 'farm_dam', 'model')\n",
        "# training part\n",
        "DATASET_PATH = os.path.join(os.getcwd(), GDRIVE_DATASET_PATH,'farm_dam')\n",
        "# google drive to coco model\n",
        "COCO_MODEL_PATH = os.path.join(GDRIVE_DATASET_PATH, \"mask_rcnn_coco.h5\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2GSw1Y0V0By"
      },
      "source": [
        "# loading modules after path is added\n",
        "from loader import DamConfig, FarmDamDataset\n",
        "import mrcnn.model as modellib"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpiGBZAmmaAh"
      },
      "source": [
        "# This code section is added for debugging, since needed to upload loader each time\n",
        "from mrcnn.config import Config\n",
        "\n",
        "class DamConfig(Config):\n",
        "    \"\"\"\n",
        "    Configuration for training on the dataset.\n",
        "    Derives from the base Config class and overrides some values.\n",
        "    \"\"\"\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"farm_dam\"\n",
        "\n",
        "    # We use a GPU with 12GB memory, which can fit two images.\n",
        "    # Adjust down if you use a smaller GPU.\n",
        "    IMAGES_PER_GPU = 2\n",
        "\n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 1  # Background + FarmDam Class\n",
        "\n",
        "    # Use small images for faster training. Set the limits of the small side\n",
        "    # the large side, and that determines the image shape.\n",
        "    IMAGE_MIN_DIM = 1024\n",
        "    IMAGE_MAX_DIM = 1024\n",
        "    \n",
        "    # Use smaller anchors because our image and objects are small\n",
        "    RPN_ANCHOR_SCALES = (16, 32, 64, 128, 256)  # anchor side in pixels\n",
        "\n",
        "    # Reduce training ROIs per image because the images are small and have\n",
        "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
        "    TRAIN_ROIS_PER_IMAGE = 16\n",
        "\n",
        "    # Non-max suppression threshold to filter RPN proposals.\n",
        "    # You can increase this during training to generate more propsals.\n",
        "    RPN_NMS_THRESHOLD = 0.7\n",
        "\n",
        "\n",
        "    # How many anchors per image to use for RPN training\n",
        "    RPN_TRAIN_ANCHORS_PER_IMAGE = 1024\n",
        "\n",
        "    # Number of training steps per epoch\n",
        "    STEPS_PER_EPOCH = 100\n",
        "\n",
        "    # Skip detections with < 80% confidence\n",
        "    DETECTION_MIN_CONFIDENCE = 0.7\n",
        "\n",
        "    WEIGHT_DECAY = 0.001\n",
        "    LEARNING_RATE = 0.001\n",
        "    VALIDATION_STEPS = 10"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKoB_loywRxC",
        "outputId": "ed4f3202-7868-4347-e78c-a285a5682c5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        }
      },
      "source": [
        "config = DamConfig()\n",
        "config.display()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     2\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.7\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 2\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  1024\n",
            "IMAGE_META_SIZE                14\n",
            "IMAGE_MIN_DIM                  1024\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [1024 1024    3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           farm_dam\n",
            "NUM_CLASSES                    2\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (16, 32, 64, 128, 256)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    1024\n",
            "STEPS_PER_EPOCH                100\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           16\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               10\n",
            "WEIGHT_DECAY                   0.001\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFb6bJb5uVv8"
      },
      "source": [
        "# training images dir\n",
        "dataset_train = FarmDamDataset()\n",
        "dataset_train.load_dam(DATASET_PATH, \"train\")\n",
        "dataset_train.prepare()\n",
        "\n",
        "# validation images dir\n",
        "dataset_val = FarmDamDataset()\n",
        "dataset_val.load_dam(DATASET_PATH, \"val\")\n",
        "dataset_val.prepare()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9mTmI36N3Ub"
      },
      "source": [
        "# Initializing augmentation\n",
        "# augmentation = iaa.SomeOf((0, 5), [\n",
        "#     iaa.Fliplr(0.5),\n",
        "#     iaa.Flipud(0.4),\n",
        "#     iaa.Crop(percent=(0, 0.5)), # random crops,\n",
        "#     iaa.Dropout([0.05, 0.2]),      # drop 5% or 20% of all pixels\n",
        "#     iaa.SomeOf((0, 4),[iaa.Affine(rotate=45),\n",
        "#                 iaa.Affine(rotate=90),\n",
        "#                 iaa.Affine(rotate=135),\n",
        "#                 iaa.Affine(rotate=180),\n",
        "#                 iaa.Affine(rotate=270)]),\n",
        "#     # Change brightness of images (80-150% of original value).\n",
        "#     iaa.Multiply((0.8, 1.5)),\n",
        "#     iaa.GaussianBlur(sigma=(0.0, 5.0))\n",
        "    \n",
        "# ])\n",
        "\n",
        "augmentation = iaa.SomeOf((0, 5), [\n",
        "    iaa.Fliplr(0.5),\n",
        "    iaa.Flipud(0.4),\n",
        "    iaa.SomeOf((0, 4),[iaa.Affine(rotate=45),\n",
        "                iaa.Affine(rotate=90),\n",
        "                iaa.Affine(rotate=135),\n",
        "                iaa.Affine(rotate=180),\n",
        "                iaa.Affine(rotate=270)]),\n",
        "    # Change brightness of images (80-150% of original value).\n",
        "    iaa.Multiply((0.8, 1.5)),\n",
        "])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbLIO6C9wDPG"
      },
      "source": [
        "def get_pretrained_model(pretrained_model_weights, model_directory, train_from_last_saved_epoch = False):\n",
        "  # Create model in training mode\n",
        "  model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=model_directory)\n",
        "  # Load weights trained on MS COCO, but skip layers that\n",
        "  # are different due to the different number of classes\n",
        "  \n",
        "  if not train_from_last_saved_epoch:\n",
        "    # Transfer learning from start\n",
        "    model.load_weights(pretrained_model_weights, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "  else:\n",
        "    # train from last saved epoch\n",
        "    weights_path = model.find_last()\n",
        "    model.load_weights(weights_path, by_name=True)\n",
        "  return model"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDoRGYyEWY3_",
        "outputId": "ab9d6343-fc01-4432-8e19-3550ab136d5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# Global variable\n",
        "# If model training is to be restarted from last saved epoch\n",
        "train_from_last_saved_epoch = False\n",
        "EPOCHS=40\n",
        "# get the model initialized in Coco dataset\n",
        "model = get_pretrained_model(COCO_MODEL_PATH, MODEL_PERS_DIR, train_from_last_saved_epoch)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From Mask_RCNN/mrcnn/model.py:600: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bG2vg3jJeMUC",
        "outputId": "5f1e6e00-cfdb-4fa8-995f-94557948cc3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train the head branches.\n",
        "model.train(dataset_train, dataset_val,\n",
        "            learning_rate=config.LEARNING_RATE,\n",
        "            epochs=EPOCHS,\n",
        "            augmentation=augmentation,\n",
        "            layers='heads')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting at epoch 0. LR=0.001\n",
            "\n",
            "Checkpoint Path: drive/My Drive/Colab Notebooks/mask_rcnn/farm_dam/model/farm_dam20201005T0942/mask_rcnn_farm_dam_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:744: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:2033: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:714: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:717: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch 1/40\n",
            "100/100 [==============================] - 286s 3s/step - loss: 2.1850 - rpn_class_loss: 0.0096 - rpn_bbox_loss: 0.8070 - mrcnn_class_loss: 0.2910 - mrcnn_bbox_loss: 0.5266 - mrcnn_mask_loss: 0.5508 - val_loss: 1.5805 - val_rpn_class_loss: 0.0130 - val_rpn_bbox_loss: 0.4915 - val_mrcnn_class_loss: 0.2957 - val_mrcnn_bbox_loss: 0.4356 - val_mrcnn_mask_loss: 0.3447\n",
            "Epoch 2/40\n",
            "100/100 [==============================] - 119s 1s/step - loss: 1.4021 - rpn_class_loss: 0.0084 - rpn_bbox_loss: 0.5054 - mrcnn_class_loss: 0.2196 - mrcnn_bbox_loss: 0.3831 - mrcnn_mask_loss: 0.2856 - val_loss: 1.3679 - val_rpn_class_loss: 0.0130 - val_rpn_bbox_loss: 0.4363 - val_mrcnn_class_loss: 0.2475 - val_mrcnn_bbox_loss: 0.3605 - val_mrcnn_mask_loss: 0.3106\n",
            "Epoch 3/40\n",
            "100/100 [==============================] - 124s 1s/step - loss: 1.2310 - rpn_class_loss: 0.0090 - rpn_bbox_loss: 0.4854 - mrcnn_class_loss: 0.1797 - mrcnn_bbox_loss: 0.2994 - mrcnn_mask_loss: 0.2575 - val_loss: 1.2663 - val_rpn_class_loss: 0.0111 - val_rpn_bbox_loss: 0.4333 - val_mrcnn_class_loss: 0.2394 - val_mrcnn_bbox_loss: 0.3229 - val_mrcnn_mask_loss: 0.2595\n",
            "Epoch 4/40\n",
            "100/100 [==============================] - 119s 1s/step - loss: 1.1275 - rpn_class_loss: 0.0084 - rpn_bbox_loss: 0.4351 - mrcnn_class_loss: 0.1700 - mrcnn_bbox_loss: 0.2746 - mrcnn_mask_loss: 0.2394 - val_loss: 1.2631 - val_rpn_class_loss: 0.0129 - val_rpn_bbox_loss: 0.3817 - val_mrcnn_class_loss: 0.2797 - val_mrcnn_bbox_loss: 0.2924 - val_mrcnn_mask_loss: 0.2964\n",
            "Epoch 5/40\n",
            "100/100 [==============================] - 118s 1s/step - loss: 1.0317 - rpn_class_loss: 0.0077 - rpn_bbox_loss: 0.3794 - mrcnn_class_loss: 0.1495 - mrcnn_bbox_loss: 0.2663 - mrcnn_mask_loss: 0.2288 - val_loss: 1.1283 - val_rpn_class_loss: 0.0084 - val_rpn_bbox_loss: 0.3896 - val_mrcnn_class_loss: 0.1479 - val_mrcnn_bbox_loss: 0.3114 - val_mrcnn_mask_loss: 0.2710\n",
            "Epoch 6/40\n",
            "100/100 [==============================] - 119s 1s/step - loss: 0.9410 - rpn_class_loss: 0.0070 - rpn_bbox_loss: 0.3284 - mrcnn_class_loss: 0.1462 - mrcnn_bbox_loss: 0.2318 - mrcnn_mask_loss: 0.2276 - val_loss: 1.2372 - val_rpn_class_loss: 0.0120 - val_rpn_bbox_loss: 0.4438 - val_mrcnn_class_loss: 0.2102 - val_mrcnn_bbox_loss: 0.2801 - val_mrcnn_mask_loss: 0.2910\n",
            "Epoch 7/40\n",
            "100/100 [==============================] - 119s 1s/step - loss: 0.9458 - rpn_class_loss: 0.0070 - rpn_bbox_loss: 0.3564 - mrcnn_class_loss: 0.1391 - mrcnn_bbox_loss: 0.2222 - mrcnn_mask_loss: 0.2212 - val_loss: 0.9302 - val_rpn_class_loss: 0.0056 - val_rpn_bbox_loss: 0.3274 - val_mrcnn_class_loss: 0.1160 - val_mrcnn_bbox_loss: 0.2351 - val_mrcnn_mask_loss: 0.2461\n",
            "Epoch 8/40\n",
            "100/100 [==============================] - 124s 1s/step - loss: 0.8856 - rpn_class_loss: 0.0065 - rpn_bbox_loss: 0.3344 - mrcnn_class_loss: 0.1223 - mrcnn_bbox_loss: 0.2087 - mrcnn_mask_loss: 0.2136 - val_loss: 1.2021 - val_rpn_class_loss: 0.0113 - val_rpn_bbox_loss: 0.3940 - val_mrcnn_class_loss: 0.2123 - val_mrcnn_bbox_loss: 0.2829 - val_mrcnn_mask_loss: 0.3016\n",
            "Epoch 9/40\n",
            "100/100 [==============================] - 127s 1s/step - loss: 0.9274 - rpn_class_loss: 0.0066 - rpn_bbox_loss: 0.3573 - mrcnn_class_loss: 0.1438 - mrcnn_bbox_loss: 0.2074 - mrcnn_mask_loss: 0.2122 - val_loss: 1.0425 - val_rpn_class_loss: 0.0103 - val_rpn_bbox_loss: 0.4031 - val_mrcnn_class_loss: 0.1705 - val_mrcnn_bbox_loss: 0.2384 - val_mrcnn_mask_loss: 0.2201\n",
            "Epoch 10/40\n",
            "100/100 [==============================] - 126s 1s/step - loss: 0.8606 - rpn_class_loss: 0.0071 - rpn_bbox_loss: 0.3188 - mrcnn_class_loss: 0.1356 - mrcnn_bbox_loss: 0.1953 - mrcnn_mask_loss: 0.2038 - val_loss: 1.2636 - val_rpn_class_loss: 0.0061 - val_rpn_bbox_loss: 0.4733 - val_mrcnn_class_loss: 0.1782 - val_mrcnn_bbox_loss: 0.2992 - val_mrcnn_mask_loss: 0.3068\n",
            "Epoch 11/40\n",
            "100/100 [==============================] - 120s 1s/step - loss: 0.8039 - rpn_class_loss: 0.0063 - rpn_bbox_loss: 0.3232 - mrcnn_class_loss: 0.1019 - mrcnn_bbox_loss: 0.1832 - mrcnn_mask_loss: 0.1894 - val_loss: 1.1507 - val_rpn_class_loss: 0.0086 - val_rpn_bbox_loss: 0.3977 - val_mrcnn_class_loss: 0.2172 - val_mrcnn_bbox_loss: 0.2521 - val_mrcnn_mask_loss: 0.2751\n",
            "Epoch 12/40\n",
            " 82/100 [=======================>......] - ETA: 19s - loss: 0.7189 - rpn_class_loss: 0.0063 - rpn_bbox_loss: 0.2524 - mrcnn_class_loss: 0.1038 - mrcnn_bbox_loss: 0.1686 - mrcnn_mask_loss: 0.1877"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67Frf3famdd3",
        "outputId": "d1b26595-51f8-44a0-b2ad-358321e6b295",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(\"Train all layers\")\n",
        "model.train(dataset_train, dataset_val,\n",
        "            learning_rate=config.LEARNING_RATE,\n",
        "            epochs=125,\n",
        "            augmentation=augmentation,\n",
        "            layers='all')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train all layers\n",
            "\n",
            "Starting at epoch 110. LR=1e-05\n",
            "\n",
            "Checkpoint Path: drive/My Drive/Colab Notebooks/mask_rcnn/farm_dam/model/farm_dam20201003T1432/mask_rcnn_farm_dam_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "conv1                  (Conv2D)\n",
            "bn_conv1               (BatchNorm)\n",
            "res2a_branch2a         (Conv2D)\n",
            "bn2a_branch2a          (BatchNorm)\n",
            "res2a_branch2b         (Conv2D)\n",
            "bn2a_branch2b          (BatchNorm)\n",
            "res2a_branch2c         (Conv2D)\n",
            "res2a_branch1          (Conv2D)\n",
            "bn2a_branch2c          (BatchNorm)\n",
            "bn2a_branch1           (BatchNorm)\n",
            "res2b_branch2a         (Conv2D)\n",
            "bn2b_branch2a          (BatchNorm)\n",
            "res2b_branch2b         (Conv2D)\n",
            "bn2b_branch2b          (BatchNorm)\n",
            "res2b_branch2c         (Conv2D)\n",
            "bn2b_branch2c          (BatchNorm)\n",
            "res2c_branch2a         (Conv2D)\n",
            "bn2c_branch2a          (BatchNorm)\n",
            "res2c_branch2b         (Conv2D)\n",
            "bn2c_branch2b          (BatchNorm)\n",
            "res2c_branch2c         (Conv2D)\n",
            "bn2c_branch2c          (BatchNorm)\n",
            "res3a_branch2a         (Conv2D)\n",
            "bn3a_branch2a          (BatchNorm)\n",
            "res3a_branch2b         (Conv2D)\n",
            "bn3a_branch2b          (BatchNorm)\n",
            "res3a_branch2c         (Conv2D)\n",
            "res3a_branch1          (Conv2D)\n",
            "bn3a_branch2c          (BatchNorm)\n",
            "bn3a_branch1           (BatchNorm)\n",
            "res3b_branch2a         (Conv2D)\n",
            "bn3b_branch2a          (BatchNorm)\n",
            "res3b_branch2b         (Conv2D)\n",
            "bn3b_branch2b          (BatchNorm)\n",
            "res3b_branch2c         (Conv2D)\n",
            "bn3b_branch2c          (BatchNorm)\n",
            "res3c_branch2a         (Conv2D)\n",
            "bn3c_branch2a          (BatchNorm)\n",
            "res3c_branch2b         (Conv2D)\n",
            "bn3c_branch2b          (BatchNorm)\n",
            "res3c_branch2c         (Conv2D)\n",
            "bn3c_branch2c          (BatchNorm)\n",
            "res3d_branch2a         (Conv2D)\n",
            "bn3d_branch2a          (BatchNorm)\n",
            "res3d_branch2b         (Conv2D)\n",
            "bn3d_branch2b          (BatchNorm)\n",
            "res3d_branch2c         (Conv2D)\n",
            "bn3d_branch2c          (BatchNorm)\n",
            "res4a_branch2a         (Conv2D)\n",
            "bn4a_branch2a          (BatchNorm)\n",
            "res4a_branch2b         (Conv2D)\n",
            "bn4a_branch2b          (BatchNorm)\n",
            "res4a_branch2c         (Conv2D)\n",
            "res4a_branch1          (Conv2D)\n",
            "bn4a_branch2c          (BatchNorm)\n",
            "bn4a_branch1           (BatchNorm)\n",
            "res4b_branch2a         (Conv2D)\n",
            "bn4b_branch2a          (BatchNorm)\n",
            "res4b_branch2b         (Conv2D)\n",
            "bn4b_branch2b          (BatchNorm)\n",
            "res4b_branch2c         (Conv2D)\n",
            "bn4b_branch2c          (BatchNorm)\n",
            "res4c_branch2a         (Conv2D)\n",
            "bn4c_branch2a          (BatchNorm)\n",
            "res4c_branch2b         (Conv2D)\n",
            "bn4c_branch2b          (BatchNorm)\n",
            "res4c_branch2c         (Conv2D)\n",
            "bn4c_branch2c          (BatchNorm)\n",
            "res4d_branch2a         (Conv2D)\n",
            "bn4d_branch2a          (BatchNorm)\n",
            "res4d_branch2b         (Conv2D)\n",
            "bn4d_branch2b          (BatchNorm)\n",
            "res4d_branch2c         (Conv2D)\n",
            "bn4d_branch2c          (BatchNorm)\n",
            "res4e_branch2a         (Conv2D)\n",
            "bn4e_branch2a          (BatchNorm)\n",
            "res4e_branch2b         (Conv2D)\n",
            "bn4e_branch2b          (BatchNorm)\n",
            "res4e_branch2c         (Conv2D)\n",
            "bn4e_branch2c          (BatchNorm)\n",
            "res4f_branch2a         (Conv2D)\n",
            "bn4f_branch2a          (BatchNorm)\n",
            "res4f_branch2b         (Conv2D)\n",
            "bn4f_branch2b          (BatchNorm)\n",
            "res4f_branch2c         (Conv2D)\n",
            "bn4f_branch2c          (BatchNorm)\n",
            "res4g_branch2a         (Conv2D)\n",
            "bn4g_branch2a          (BatchNorm)\n",
            "res4g_branch2b         (Conv2D)\n",
            "bn4g_branch2b          (BatchNorm)\n",
            "res4g_branch2c         (Conv2D)\n",
            "bn4g_branch2c          (BatchNorm)\n",
            "res4h_branch2a         (Conv2D)\n",
            "bn4h_branch2a          (BatchNorm)\n",
            "res4h_branch2b         (Conv2D)\n",
            "bn4h_branch2b          (BatchNorm)\n",
            "res4h_branch2c         (Conv2D)\n",
            "bn4h_branch2c          (BatchNorm)\n",
            "res4i_branch2a         (Conv2D)\n",
            "bn4i_branch2a          (BatchNorm)\n",
            "res4i_branch2b         (Conv2D)\n",
            "bn4i_branch2b          (BatchNorm)\n",
            "res4i_branch2c         (Conv2D)\n",
            "bn4i_branch2c          (BatchNorm)\n",
            "res4j_branch2a         (Conv2D)\n",
            "bn4j_branch2a          (BatchNorm)\n",
            "res4j_branch2b         (Conv2D)\n",
            "bn4j_branch2b          (BatchNorm)\n",
            "res4j_branch2c         (Conv2D)\n",
            "bn4j_branch2c          (BatchNorm)\n",
            "res4k_branch2a         (Conv2D)\n",
            "bn4k_branch2a          (BatchNorm)\n",
            "res4k_branch2b         (Conv2D)\n",
            "bn4k_branch2b          (BatchNorm)\n",
            "res4k_branch2c         (Conv2D)\n",
            "bn4k_branch2c          (BatchNorm)\n",
            "res4l_branch2a         (Conv2D)\n",
            "bn4l_branch2a          (BatchNorm)\n",
            "res4l_branch2b         (Conv2D)\n",
            "bn4l_branch2b          (BatchNorm)\n",
            "res4l_branch2c         (Conv2D)\n",
            "bn4l_branch2c          (BatchNorm)\n",
            "res4m_branch2a         (Conv2D)\n",
            "bn4m_branch2a          (BatchNorm)\n",
            "res4m_branch2b         (Conv2D)\n",
            "bn4m_branch2b          (BatchNorm)\n",
            "res4m_branch2c         (Conv2D)\n",
            "bn4m_branch2c          (BatchNorm)\n",
            "res4n_branch2a         (Conv2D)\n",
            "bn4n_branch2a          (BatchNorm)\n",
            "res4n_branch2b         (Conv2D)\n",
            "bn4n_branch2b          (BatchNorm)\n",
            "res4n_branch2c         (Conv2D)\n",
            "bn4n_branch2c          (BatchNorm)\n",
            "res4o_branch2a         (Conv2D)\n",
            "bn4o_branch2a          (BatchNorm)\n",
            "res4o_branch2b         (Conv2D)\n",
            "bn4o_branch2b          (BatchNorm)\n",
            "res4o_branch2c         (Conv2D)\n",
            "bn4o_branch2c          (BatchNorm)\n",
            "res4p_branch2a         (Conv2D)\n",
            "bn4p_branch2a          (BatchNorm)\n",
            "res4p_branch2b         (Conv2D)\n",
            "bn4p_branch2b          (BatchNorm)\n",
            "res4p_branch2c         (Conv2D)\n",
            "bn4p_branch2c          (BatchNorm)\n",
            "res4q_branch2a         (Conv2D)\n",
            "bn4q_branch2a          (BatchNorm)\n",
            "res4q_branch2b         (Conv2D)\n",
            "bn4q_branch2b          (BatchNorm)\n",
            "res4q_branch2c         (Conv2D)\n",
            "bn4q_branch2c          (BatchNorm)\n",
            "res4r_branch2a         (Conv2D)\n",
            "bn4r_branch2a          (BatchNorm)\n",
            "res4r_branch2b         (Conv2D)\n",
            "bn4r_branch2b          (BatchNorm)\n",
            "res4r_branch2c         (Conv2D)\n",
            "bn4r_branch2c          (BatchNorm)\n",
            "res4s_branch2a         (Conv2D)\n",
            "bn4s_branch2a          (BatchNorm)\n",
            "res4s_branch2b         (Conv2D)\n",
            "bn4s_branch2b          (BatchNorm)\n",
            "res4s_branch2c         (Conv2D)\n",
            "bn4s_branch2c          (BatchNorm)\n",
            "res4t_branch2a         (Conv2D)\n",
            "bn4t_branch2a          (BatchNorm)\n",
            "res4t_branch2b         (Conv2D)\n",
            "bn4t_branch2b          (BatchNorm)\n",
            "res4t_branch2c         (Conv2D)\n",
            "bn4t_branch2c          (BatchNorm)\n",
            "res4u_branch2a         (Conv2D)\n",
            "bn4u_branch2a          (BatchNorm)\n",
            "res4u_branch2b         (Conv2D)\n",
            "bn4u_branch2b          (BatchNorm)\n",
            "res4u_branch2c         (Conv2D)\n",
            "bn4u_branch2c          (BatchNorm)\n",
            "res4v_branch2a         (Conv2D)\n",
            "bn4v_branch2a          (BatchNorm)\n",
            "res4v_branch2b         (Conv2D)\n",
            "bn4v_branch2b          (BatchNorm)\n",
            "res4v_branch2c         (Conv2D)\n",
            "bn4v_branch2c          (BatchNorm)\n",
            "res4w_branch2a         (Conv2D)\n",
            "bn4w_branch2a          (BatchNorm)\n",
            "res4w_branch2b         (Conv2D)\n",
            "bn4w_branch2b          (BatchNorm)\n",
            "res4w_branch2c         (Conv2D)\n",
            "bn4w_branch2c          (BatchNorm)\n",
            "res5a_branch2a         (Conv2D)\n",
            "bn5a_branch2a          (BatchNorm)\n",
            "res5a_branch2b         (Conv2D)\n",
            "bn5a_branch2b          (BatchNorm)\n",
            "res5a_branch2c         (Conv2D)\n",
            "res5a_branch1          (Conv2D)\n",
            "bn5a_branch2c          (BatchNorm)\n",
            "bn5a_branch1           (BatchNorm)\n",
            "res5b_branch2a         (Conv2D)\n",
            "bn5b_branch2a          (BatchNorm)\n",
            "res5b_branch2b         (Conv2D)\n",
            "bn5b_branch2b          (BatchNorm)\n",
            "res5b_branch2c         (Conv2D)\n",
            "bn5b_branch2c          (BatchNorm)\n",
            "res5c_branch2a         (Conv2D)\n",
            "bn5c_branch2a          (BatchNorm)\n",
            "res5c_branch2b         (Conv2D)\n",
            "bn5c_branch2b          (BatchNorm)\n",
            "res5c_branch2c         (Conv2D)\n",
            "bn5c_branch2c          (BatchNorm)\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:2033: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 111/125\n",
            "20/20 [==============================] - 594s 30s/step - loss: 2.1760 - rpn_class_loss: 0.0377 - rpn_bbox_loss: 1.7014 - mrcnn_class_loss: 0.0098 - mrcnn_bbox_loss: 0.2066 - mrcnn_mask_loss: 0.2204 - val_loss: 2.4016 - val_rpn_class_loss: 0.1269 - val_rpn_bbox_loss: 1.5225 - val_mrcnn_class_loss: 0.0257 - val_mrcnn_bbox_loss: 0.3545 - val_mrcnn_mask_loss: 0.3719\n",
            "Epoch 112/125\n",
            "20/20 [==============================] - 44s 2s/step - loss: 2.0934 - rpn_class_loss: 0.0490 - rpn_bbox_loss: 1.5096 - mrcnn_class_loss: 0.0102 - mrcnn_bbox_loss: 0.2023 - mrcnn_mask_loss: 0.3223 - val_loss: 2.4401 - val_rpn_class_loss: 0.1291 - val_rpn_bbox_loss: 1.5181 - val_mrcnn_class_loss: 0.0258 - val_mrcnn_bbox_loss: 0.3781 - val_mrcnn_mask_loss: 0.3890\n",
            "Epoch 113/125\n",
            "20/20 [==============================] - 49s 2s/step - loss: 2.3265 - rpn_class_loss: 0.0403 - rpn_bbox_loss: 1.8153 - mrcnn_class_loss: 0.0067 - mrcnn_bbox_loss: 0.2162 - mrcnn_mask_loss: 0.2479 - val_loss: 2.4116 - val_rpn_class_loss: 0.1271 - val_rpn_bbox_loss: 1.5107 - val_mrcnn_class_loss: 0.0243 - val_mrcnn_bbox_loss: 0.3695 - val_mrcnn_mask_loss: 0.3800\n",
            "Epoch 114/125\n",
            "20/20 [==============================] - 49s 2s/step - loss: 1.9389 - rpn_class_loss: 0.0519 - rpn_bbox_loss: 1.2853 - mrcnn_class_loss: 0.0090 - mrcnn_bbox_loss: 0.2707 - mrcnn_mask_loss: 0.3221 - val_loss: 2.3998 - val_rpn_class_loss: 0.1263 - val_rpn_bbox_loss: 1.5273 - val_mrcnn_class_loss: 0.0258 - val_mrcnn_bbox_loss: 0.3535 - val_mrcnn_mask_loss: 0.3668\n",
            "Epoch 115/125\n",
            "20/20 [==============================] - 47s 2s/step - loss: 2.5403 - rpn_class_loss: 0.0575 - rpn_bbox_loss: 1.8565 - mrcnn_class_loss: 0.0146 - mrcnn_bbox_loss: 0.2571 - mrcnn_mask_loss: 0.3546 - val_loss: 2.4092 - val_rpn_class_loss: 0.1279 - val_rpn_bbox_loss: 1.5414 - val_mrcnn_class_loss: 0.0254 - val_mrcnn_bbox_loss: 0.3506 - val_mrcnn_mask_loss: 0.3640\n",
            "Epoch 116/125\n",
            "20/20 [==============================] - 48s 2s/step - loss: 2.4751 - rpn_class_loss: 0.0553 - rpn_bbox_loss: 1.9231 - mrcnn_class_loss: 0.0117 - mrcnn_bbox_loss: 0.2206 - mrcnn_mask_loss: 0.2643 - val_loss: 2.3556 - val_rpn_class_loss: 0.1123 - val_rpn_bbox_loss: 1.5205 - val_mrcnn_class_loss: 0.0237 - val_mrcnn_bbox_loss: 0.3448 - val_mrcnn_mask_loss: 0.3543\n",
            "Epoch 117/125\n",
            "20/20 [==============================] - 49s 2s/step - loss: 2.3599 - rpn_class_loss: 0.0386 - rpn_bbox_loss: 1.7778 - mrcnn_class_loss: 0.0075 - mrcnn_bbox_loss: 0.2518 - mrcnn_mask_loss: 0.2842 - val_loss: 2.4313 - val_rpn_class_loss: 0.1312 - val_rpn_bbox_loss: 1.5134 - val_mrcnn_class_loss: 0.0249 - val_mrcnn_bbox_loss: 0.3720 - val_mrcnn_mask_loss: 0.3898\n",
            "Epoch 118/125\n",
            "20/20 [==============================] - 49s 2s/step - loss: 2.0970 - rpn_class_loss: 0.0567 - rpn_bbox_loss: 1.4552 - mrcnn_class_loss: 0.0091 - mrcnn_bbox_loss: 0.2937 - mrcnn_mask_loss: 0.2823 - val_loss: 2.4292 - val_rpn_class_loss: 0.1321 - val_rpn_bbox_loss: 1.5580 - val_mrcnn_class_loss: 0.0254 - val_mrcnn_bbox_loss: 0.3473 - val_mrcnn_mask_loss: 0.3663\n",
            "Epoch 119/125\n",
            "20/20 [==============================] - 50s 3s/step - loss: 2.3696 - rpn_class_loss: 0.0637 - rpn_bbox_loss: 1.5930 - mrcnn_class_loss: 0.0129 - mrcnn_bbox_loss: 0.3217 - mrcnn_mask_loss: 0.3783 - val_loss: 2.4346 - val_rpn_class_loss: 0.1291 - val_rpn_bbox_loss: 1.5521 - val_mrcnn_class_loss: 0.0246 - val_mrcnn_bbox_loss: 0.3573 - val_mrcnn_mask_loss: 0.3716\n",
            "Epoch 120/125\n",
            "20/20 [==============================] - 54s 3s/step - loss: 2.1691 - rpn_class_loss: 0.0554 - rpn_bbox_loss: 1.5866 - mrcnn_class_loss: 0.0127 - mrcnn_bbox_loss: 0.2388 - mrcnn_mask_loss: 0.2756 - val_loss: 2.3855 - val_rpn_class_loss: 0.1243 - val_rpn_bbox_loss: 1.5178 - val_mrcnn_class_loss: 0.0272 - val_mrcnn_bbox_loss: 0.3459 - val_mrcnn_mask_loss: 0.3704\n",
            "Epoch 121/125\n",
            "20/20 [==============================] - 51s 3s/step - loss: 2.3550 - rpn_class_loss: 0.0509 - rpn_bbox_loss: 1.7093 - mrcnn_class_loss: 0.0123 - mrcnn_bbox_loss: 0.2336 - mrcnn_mask_loss: 0.3489 - val_loss: 2.4199 - val_rpn_class_loss: 0.1300 - val_rpn_bbox_loss: 1.5290 - val_mrcnn_class_loss: 0.0250 - val_mrcnn_bbox_loss: 0.3635 - val_mrcnn_mask_loss: 0.3723\n",
            "Epoch 122/125\n",
            "20/20 [==============================] - 49s 2s/step - loss: 2.1862 - rpn_class_loss: 0.0519 - rpn_bbox_loss: 1.5309 - mrcnn_class_loss: 0.0115 - mrcnn_bbox_loss: 0.2811 - mrcnn_mask_loss: 0.3108 - val_loss: 2.4149 - val_rpn_class_loss: 0.1160 - val_rpn_bbox_loss: 1.5022 - val_mrcnn_class_loss: 0.0273 - val_mrcnn_bbox_loss: 0.3809 - val_mrcnn_mask_loss: 0.3885\n",
            "Epoch 123/125\n",
            "20/20 [==============================] - 48s 2s/step - loss: 2.4244 - rpn_class_loss: 0.0563 - rpn_bbox_loss: 1.6767 - mrcnn_class_loss: 0.0178 - mrcnn_bbox_loss: 0.3278 - mrcnn_mask_loss: 0.3458 - val_loss: 2.4363 - val_rpn_class_loss: 0.1339 - val_rpn_bbox_loss: 1.5441 - val_mrcnn_class_loss: 0.0262 - val_mrcnn_bbox_loss: 0.3594 - val_mrcnn_mask_loss: 0.3727\n",
            "Epoch 124/125\n",
            "20/20 [==============================] - 48s 2s/step - loss: 2.5637 - rpn_class_loss: 0.0523 - rpn_bbox_loss: 1.9652 - mrcnn_class_loss: 0.0118 - mrcnn_bbox_loss: 0.2216 - mrcnn_mask_loss: 0.3128 - val_loss: 2.3880 - val_rpn_class_loss: 0.1213 - val_rpn_bbox_loss: 1.5426 - val_mrcnn_class_loss: 0.0237 - val_mrcnn_bbox_loss: 0.3465 - val_mrcnn_mask_loss: 0.3540\n",
            "Epoch 125/125\n",
            "20/20 [==============================] - 47s 2s/step - loss: 2.3554 - rpn_class_loss: 0.0473 - rpn_bbox_loss: 1.7769 - mrcnn_class_loss: 0.0100 - mrcnn_bbox_loss: 0.2286 - mrcnn_mask_loss: 0.2926 - val_loss: 2.4101 - val_rpn_class_loss: 0.1262 - val_rpn_bbox_loss: 1.5254 - val_mrcnn_class_loss: 0.0246 - val_mrcnn_bbox_loss: 0.3592 - val_mrcnn_mask_loss: 0.3747\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_oNu_s03VW4"
      },
      "source": [
        ""
      ]
    }
  ]
}